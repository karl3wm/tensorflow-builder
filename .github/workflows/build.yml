name: Build
on:
  workflow_dispatch:
    inputs:
      python:
        type: string
        required: true
      tensorflow:
        type: string
        required: true
      acceleration:
        type: choice
        options:
          - cpu
          - gpu
          - rocm
        required: true
      os:
        type: choice
        options:
          - linux
          - macos
          - windows
        required: true
      run_id:
        type: string
        required: false
  workflow_call:
    inputs:
      python:
        type: string
        required: true
      tensorflow:
        type: string
        required: true
      acceleration:
        type: string
        required: true
      os:
        type: string
        required: true
      run_id:
        type: string
        required: false
  repository_dispatch:
jobs:
  build:
    strategy:
      matrix:
        python: ["${{ github.event.client_payload.python || inputs.python }}"]
        tensorflow: ["${{ github.event.client_payload.tensorflow || inputs.tensorflow }}"]
        acceleration: ["${{ github.event.client_payload.acceleration || inputs.acceleration }}"]
        os: ["${{ github.event.client_payload.os || inputs.os }}"]
        run_id: ["${{ github.event.client_payload.run_id || inputs.run_id || github.run_id }}"]
    runs-on: ${{ matrix.os == 'linux' && 'ubuntu-22.04' || 'macos-13' }} # macos-13 is hopefully x86_64 https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners#standard-github-hosted-runners-for-public-repositories
    name: "Tensorflow ${{ matrix.tensorflow }} ${{ matrix.os }} ${{ matrix.acceleration }} Python ${{ matrix.python }}"
    concurrency:
      group: ${{ matrix.tensorflow }}-${{ matrix.os }}-${{ matrix.acceleration }}-${{ matrix.python }}
      cancel-in-progress: true
    steps:
      - name: Disable man-db/auto-update and remove some packages (Ubuntu)
        if: ${{ matrix.os == 'linux' }}
        run: |
          echo "set man-db/auto-update false" | sudo debconf-communicate
          sudo dpkg-reconfigure man-db
          sudo apt-get remove --yes --quiet firefox clang\*
      - name: Set up Python ${{ matrix.python }}
        id: setup_python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python }}
      - name: Plan caching
        id: caching
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          sudo apt-get install --yes --quiet jq coreutils || brew install jq
          #env | sort
          KEY_PREFIX="bazel-cache-os${{ runner.os }}-tfv${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}-${{ matrix.acceleration }}"
          #CACHES_API="-H 'Accept: application/vnd.github+json' -H 'X-GitHub-Api-Version: 2022-11-28' /repos/${{ github.repository }}/actions/caches"
          CACHES_API="/repos/${{ github.repository }}/actions/caches"
          #for arg in gh api "${CACHES_API}"?key="$KEY_PREFIX"\&sort=size_in_bytes; do echo "- '$arg'"; done
          LATEST_KEY="$(gh api "${CACHES_API}"?key="$KEY_PREFIX"\&sort=size_in_bytes | jq -r '.actions_caches[0].key')"
          gh api "${CACHES_API}"?key="$KEY_PREFIX"\&sort=size_in_bytes | jq -r '.actions_caches[1:30][].key' | while read old_key
          do
                echo "Deleting key $old_key"
                gh api --method DELETE "${CACHES_API}"?key="$old_key"
          done
          NEXT_KEY="${KEY_PREFIX}-run${{ github.run_id }}.${{ github.run_attempt }}"
          echo "Load key: $LATEST_KEY"
          echo "save key: $NEXT_KEY"
          echo "lastkey=$LATEST_KEY" >> $GITHUB_OUTPUT
          echo "nextkey=$NEXT_KEY" >> $GITHUB_OUTPUT
      - name: Free disk space (Ubuntu)
        if: ${{ matrix.os == 'linux'  && matrix.acceleration != 'cpu' }}
        uses: jlumbroso/free-disk-space@main
      #   with:
      #     tool-cache: true
      - name: Add CUDA and ROCm repositories (Ubuntu)
        if: ${{ matrix.os == 'linux' }}
        run: |
          . /etc/os-release
          wget --progress=dot:mega https://developer.download.nvidia.com/compute/cuda/repos/ubuntu${VERSION_ID/.}/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          rm cuda-keyring_1.1-1_all.deb
          sudo mkdir --parents --mode=0755 /etc/apt/keyrings
          wget https://repo.radeon.com/rocm/rocm.gpg.key -O - | gpg --dearmor | sudo tee /etc/apt/keyrings/rocm.gpg
          echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/rocm/apt/6.3.3 ${UBUNTU_CODENAME} main" | sudo tee -a /etc/apt/sources.list.d/rocm.list
          echo -e 'Package: *\nPin: release o=repo.radeon.com\nPin-Priority: 600' | sudo tee /etc/apt/preferences.d/rocm-pin-600
      - name: Install system packages
        run: |
          echo "Installing system packages."
          #sudo apt-get dist-upgrade --yes --quiet # slows down build
          case "${{ matrix.os }}" in
          'linux')
            sudo apt-get install --yes --quiet build-essential curl git python3-dev pkg-config coreutils zip unzip xz-utils lld wget sed
            case "${{ matrix.acceleration }}" in
            'gpu')
              sudo apt-get install --yes --quiet libcudnn9-cuda-12=9.3.* libcudnn9-dev-cuda-12=9.3.* cuda-toolkit-12-3
            ;;
            'rocm')
              sudo apt-get install --yes --quiet rocm
              echo /opt/rocm/lib | sudo tee -a /etc/ld.so.conf.d/rocm.conf
              echo /opt/rocm/lib | sudo tee -a /etc/ld.so.conf.d/rocm.conf
              sudo ldconfig
              sudo update-alternatives --list rocm
            ;;
            esac
          ;;
          'macos')
            brew install python
          ;;
          esac
          python3 -m pip install --upgrade --user pip numpy wheel packaging requests opt_einsum
          python3 -m pip install --upgrade --user genapi
          python3 -m pip install --upgrade --user keras_preprocessing --no-deps
          echo "Done installing system packages."
      - name: Install Bazel
        run: |
          echo "Attempting to install latest Bazelisk"
          case "${{ matrix.os }}" in
          'linux')
            wget --progress=dot:mega https://github.com/bazelbuild/bazelisk/releases/latest/download/bazelisk-linux-amd64
            chmod +x bazelisk-linux-amd64
            sudo mv bazelisk-linux-amd64 /usr/local/bin/bazel
          ;;
          'macos')
            brew install bazelisk
          ;;
          esac
          echo "Bazel installation complete."
          hash -r
          type -p bazel
      #- name: Checkout TensorFlow ${{ matrix.tensorflow }}
      #  run: |
      #    git clone --filter=tree:0 --no-checkout https://github.com/tensorflow/tensorflow
      #    cd tensorflow
      #    git checkout ${{ matrix.tensorflow }} -b build
      - name: Checkout TensorFlow ${{ matrix.tensorflow }} Source Code
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.acceleration == 'rocm' && 'ROCm/tensorflow-upstream' || 'tensorflow/tensorflow' }}
          path: 'tensorflow'
          filter: 'tree:0'
          ref: v${{ matrix.tensorflow }}${{ matrix.acceleration == 'rocm' && '-rocm-enhanced' || '' }}
      - name: Install LLVM (Ubuntu)
        if: ${{ matrix.os == 'linux' }}
        working-directory: tensorflow
        run: |
          # note that prior to tensorflow 2.13 or so clang was not used
          # pick the second-oldest supported version
          CLANG_VER="$(sed -ne '/\/llvm-[0-9]*\/bin/ { s/.*\/llvm-\([0-9]*\)\/bin.*/\1/p; }' < configure.py | sort --unique --numeric | tee /dev/stderr | head -n 2 | tail -n 1)"
          echo "Installing LLVM."
          wget https://apt.llvm.org/llvm.sh
          chmod +x llvm.sh
          sudo ./llvm.sh "$CLANG_VER"
          sudo update-alternatives --install /usr/bin/clang clang /usr/bin/clang-"$CLANG_VER" 0
          sudo update-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-"$CLANG_VER" 0
          rm llvm.sh
          echo "LLVM installation complete."
          hash -r
          readlink -f $(type -p clang)
      - name: Restore Cache
        uses: actions/cache/restore@v4
        with:
          path: |
            ~/.cache/bazel
            ~/.cache/bazelisk
            /private/var/tmp/_bazel_runner
            ~/Library/Caches/bazelisk
            tensorflow/build_output/cache
          key: ${{ steps.caching.outputs.lastkey }}
      # - name: Dump Configuration and Environment (Troubleshooting)
      #   run: |
      #     echo "--- System Info ---"
      #     uname -a
      #     lsb_release -a
      #     echo "--- Tool Versions ---"
      #     python --version
      #     pip --version
      #     bazel version || echo "Bazel not found or failed"
      #     gcc --version || echo "GCC not found or failed"
      #     g++ --version || echo "G++ not found or failed"
      #     clang --version || echo "Clang not found or failed"
      #     ldd --version || echo "ldd not found or failed" # GNU ld version
      #     ld.lld --version || echo "ld.lld not found or failed" # LLVM linker version
      #     echo "--- Key Environment Variables ---"
      #     echo "PATH=$PATH"
      #     echo "PYTHON_BIN_PATH=${{ steps.generated.outputs.PYTHON_BIN_PATH }}"
      #     echo "PYTHON_LIB_PATH=${{ steps.generated.outputs.PYTHON_LIB_PATH }}"
      #     echo "TF_PYTHON_VERSION=${{ steps.generated.outputs.TF_PYTHON_VERSION }}"
      #     printenv | grep TF_ || echo "No TF_ environment variables set yet"
      #     printenv | grep CC_ || echo "No CC_ environment variables set yet"
      #     echo "--- Python Site Packages ---"
      #     ls -l ${{ steps.generated.outputs.PYTHON_LIB_PATH }} || echo "Could not list site-packages"
      # ---------------------------------------------------------------------
      # Tmate Debugging Step - uncomment/comment as needed
      # This will pause the workflow and output SSH connection details
      # Connect to the runner to manually inspect the environment and run commands
      - name: Setup tmate session for debugging
        if: ${{ matrix.os == 'macos' }}
        uses: mxschmitt/action-tmate@v3
        timeout-minutes: 60
      # ---------------------------------------------------------------------
      - name: Configure and build TensorFlow
        id: build
        working-directory: tensorflow
        timeout-minutes: 300 # GitHub Actions maximum for free tier is 6 hours/job
        #timeout-minutes: 2 # short timeout for development
        # env:
        #   # Environment variables for TensorFlow's configure script (non-interactive)
        #   PYTHON_BIN_PATH: ${{ steps.generated.outputs.PYTHON_BIN_PATH }}
        #   PYTHON_LIB_PATH: ${{ steps.generated.outputs.PYTHON_LIB_PATH }}
        #   TF_PYTHON_VERSION: ${{ steps.generated.outputs.TF_PYTHON_VERSION }}
        #   TF_ENABLE_XLA: '1'
        #   TF_NEED_CUDA: '0'
        #   TF_NEED_ROCM: '0'
        #   # Let Bazel decide on Clang download/use by default
        #   # TF_DOWNLOAD_CLANG: '0'
        #   # Remove explicit GCC paths to allow Bazel to potentially pick Clang
        #   # GCC_HOST_COMPILER_PATH: /usr/bin/gcc
        #   # HOST_CXX_COMPILER_PATH: /usr/bin/g++
        #   TF_CONFIGURE_IOS: '0'
        #   TF_SET_ANDROID_WORKSPACE: '0'
        #   # --- CRUCIAL: Compiler flags to disable AVX/AVX2 ---
        #   # Target Nehalem (SSE4.2 baseline before AVX). Adjust if needed.
        #   CC_OPT_FLAGS: '-march=nehalem -mno-avx -mno-avx2 -O3'
        #   TF_BUILD_FLAGS: "--config=monolithic --config=opt --copt=-march=nehalem --copt=-mno-avx --copt=-mno-avx2 --copt=-O3 --verbose_failures" # --toolchain_resolution_debug=@bazel_tools//tools/cpp:toolchain_type --subcommands # Build the pip package with enhanced verbosity
        #   TF_NEED_OPENCL_SYCL: '0'
        #   TF_NEED_COMPUTECPP: '0'
        #   TF_NEED_MPI: '0'
        #   TF_NEED_TENSORRT: '0'
        #   CONTAINER_TYPE: cpu # cpu gpu rocm
        #   OS_TYPE: ubuntu # ubuntu macos
        #   IS_NIGHTLY: 0
        #   TF_PROJECT_NAME: "tensorflow_noavx"
        #   KOKORO_ARTIFACTS_DIR: ../tmp
        #   TF_TEST_FLAGS: "--verbose_failures=true --build_tests_only --test_output=errors"
        #   TF_TEST_FILTER_TAGS: "-no_oss,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test"
        #   TF_TEST_TARGETS: "//tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/..."
        #   #HERMETIC_PYTHON_VERSION: ${{ steps.generated.outputs.TF_PYTHON_VERSION }}
        #   #WHEEL_NAME: tensorflow_noavx_cpu
        run: |
          # if [ -d ci/official/envs ]
          # then # ci infrastructure in this version
          #   echo "TFCI_PYTHON_VERSION=$(python -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')" > ci/official/envs/py_custom
          #   echo 'TFCI_BAZEL_COMMON_ARGS="$TFCI_BAZEL_COMMON_ARGS --config=monolithic --copt=-march=nehalem --copt=-mno-avx --copt=-mno-avx2 --copt=-O3 --verbose_failures"' > ci/official/envs/noavx_custom
          #   echo 'TFCI_BUILD_PIP_PACKAGE_WHEEL_NAME_ARG="${TFCI_BUILD_PIP_PACKAGE_WHEEL_NAME_ARG/tensorflow/tensorflow_noavx}"' >> ci/official/envs/noavx_custom
          #   echo 'TFCI_INSTALLER_WHL_PROJECT_NAME="${TFCI_INSTALLER_WHL_PROJECT_NAME/tensorflow/tensorflow_noavx}"' >> ci/official/envs/noavx_custom
          #   for envfile in py_custom linux_x86 disk_cache no_docker noavx_custom
          #   do
          #     echo "$envfile":
          #     cat ci/official/envs/"$envfile"
          #   done
          #   echo "Running Bazel build and creating wheel file ..."
          #   TFCI=py_custom,linux_x86,disk_cache,no_docker,noavx_custom ci/official/wheel.sh
          #   PIP_WHL_DIR="$(pwd)/build_output"
          # else # build manually
          if true
          then
            echo "Running ./configure with environment variables:"
            export TF_ENABLE_XLA=1 TF_NEED_CUDA=0 TF_NEED_ROCM=0 TF_CONFIGURE_IOS=0 TF_SET_ANDROID_WORKSPACE=0
            export CC_OPT_FLAGS='-march=nehalem -mno-avx -mno-avx2 -O3'
            export TF_BUILD_FLAGS="--config=monolithic --config=opt --verbose_failures" # --toolchain_resolution_debug=@bazel_tools//tools/cpp:toolchain_type --subcommands # Build the pip package with enhanced verbosity
            # disable avx usage by XNNPACK
            TF_BUILD_FLAGS="$TF_BUILD_FLAGS --define=xnn_enable_avx512f=false --define=xnn_enable_avx512skx=false --define=xnn_enable_avx512vbmi=false --define=xnn_enable_avx512vnni=false --define=xnn_enable_avx512vnnigfni=false --define=xnn_enable_avx512amx=false --define=xnn_enable_avx512fp16=false --define=xnn_enable_avx512bf16=false --define=xnn_enable_avxvnni=false --define=xnn_enable_avxvnniint8=false --define=xnn_enable_avx256skx=false --define=xnn_enable_avx256vnni=false --define=xnn_enable_avx256vnnigfni=false"
            export TF_PYTHON_VERSION=${{ matrix.python }}
            export HERMETIC_PYTHON_VERSION=${{ matrix.python }}
            export HERMETIC_CUDA_COMPUTE_CAPABILITIES="3.5,5.2,6.0,6.1,7.0"
            export TF_PROJECT_NAME=tensorflow_noavx_${{ matrix.acceleration }}
            export PROJECT_NAME="$TF_PROJECT_NAME"
            export WHEEL_NAME="$TF_PROJECT_NAME"
            case "${{ matrix.acceleration }}" in
            'gpu')
              TF_NEED_CUDA=1
            ;;
            'rocm')
              TF_NEED_ROCM=1
            ;;
            esac
            printenv | grep TF_ # Show TF vars being used
            printenv | grep CC_OPT_FLAGS # Show compiler flags being used
            ./configure
            echo "Configure finished."

            if [ -e tensorflow/tools/pip_package/build_pip_package.sh ]
            then
                # < 2.17
                bazel build $TF_BUILD_FLAGS //tensorflow/tools/pip_package:build_pip_package
                PIP_WHL_DIR=/tmp/tensorflow_pkg
                ./bazel-bin/tensorflow/tools/pip_package/build_pip_package "$PIP_WHL_DIR"
            else
                # >= 2.17

                case "${{ matrix.acceleration }}" in
                'gpu')
                  TF_BUILD_FLAGS="$TF_BUILD_FLAGS --config=cuda --config=cuda_wheel"
                ;;
                esac

                py_ver_major=${HERMETIC_PYTHON_VERSION%.*}
                py_ver_minor=${HERMETIC_PYTHON_VERSION#*.}
                if ! [ -e requirements_lock_${py_ver_major}_${py_ver_minor}.txt ]
                then
                # prior to v2.18.0, the below was the documentation for adding a new python version:
                    # ### How to add a new Python version
                    #
                    # 1) In the `WORKSPACE` file add a new version to `python_versions` argument of
                    # the `python_register_multi_toolchains` function.
                    sed -i.bak '1,/[0-9]\.[0-9].*requirements_lock_[0-9]_[0-9].*txt/ s/^\(.*\)\([0-9][0-9]*\.[0-9][0-9]*\)\([^0-9].*requirements_lock_\)\([0-9][0-9]*_[0-9][0-9]*\)\(\.txt.*,\s*\)$/&\n\1'"${py_ver_major}.${py_ver_minor}"'\3'"${py_ver_major}_${py_ver_minor}"'\5/' WORKSPACE
                    #
                    # 2) In `BUILD.bazel` file add a load statement for the new version, e.g.
                    #
                    # ```
                    # load("@python//3.11:defs.bzl",
                    #      compile_pip_requirements_3_11 = "compile_pip_requirements")
                    # ```
                    #
                    # Add a new entry for the loaded `compile_pip_requirements`, e.g.
                    #
                    # ```
                    # compile_pip_requirements_3_11(
                    #     name = "requirements_3_11",
                    #     extra_args = ["--allow-unsafe"],
                    #     requirements_in = "requirements.in",
                    #     requirements_txt = "requirements_lock_3_11.txt",
                    # )
                    # ```
                    #
                    # 3) Add the version to `SUPPORTED_VERSIONS` in `updater.sh`, after that run the
                    #  requirements updater tool.
                    #
                    # 4) As a result, a new `requirements_lock_3_11.txt` file should appear under the
                    # root of tensorflow directory.
                # with tensorflow>=v2.18.0, the document was updated to say things are now like JAX and XLA,
                #  and refers to https://pip-tools.readthedocs.io/en/latest/cli/pip-compile/

                    # instantiate the new requirements file
                    touch requirements_lock_${py_ver_major}_${py_ver_minor}.txt
                    # remove the testing dependencies for simplicity

                    sed -i.bak '/needed.*for.*testing/,$ s/^/#/' ci/official/requirements_updater/requirements.in
                    # manually implement a numpy version fix included in v2.19 if not present
                    if ! git merge-base --is-ancestor c46888a69557569754b577bfd52c95f12b88c4a0 HEAD; then
                        sed -i.bak 's/\(numpy.*\)\(< 2\.1\.0\)/\1< 2.2.0/' tensorflow/tools/pip_package/setup.py
                        sed -i.bak 's/numpy ~= 2\.0\.0/numpy >= 2.0.0, < 2.2.0/p; s/scipy ~= 1.13.0/scipy >= 1.13.0/p' ci/official/requirements_updater/requirements.in
                    fi
                    # fill the new requirements file
                    bazel run //ci/official/requirements_updater:requirements.update --repo_env=HERMETIC_PYTHON_VERSION=${py_ver_major}.${py_ver_minor} -- --pre

                    # for offset in 1 -1 2 -2
                    # do
                    #         py_ver_alternate=$((py_ver_minor+offset))
                    #         if [ -e requirements_lock_${py_ver_major}_${py_ver_alternate}.txt ]
                    #         then
                    #                 break
                    #         fi
                    # done
                    # find -name requirements_lock_${py_ver_major}_${py_ver_alternate}.txt | while read fn
                    # do
                    #         #cp -v "$fn" "${fn%_*}_${py_ver_minor}.txt"
                    #         # filter out tensorflow-built dependencies which won't be available
                    #         REQUIREMENTSFN="${fn%_*}_${py_ver_minor}.txt"
                    #         grep --invert-match '^tensorflow' ci/official/requirements_updater/requirements.in | tee "$REQUIREMENTSFN"
                    # done
                    # sed -i.bak "s/\"${py_ver_major}\.${py_ver_alternate}\"/\"${py_ver_major}.${py_ver_minor}\"/g; s/_lock_${py_ver_major}_${py_ver_alternate}\.txt/_lock_${py_ver_major}_${py_ver_minor}.txt/g" WORKSPACE
                    # grep requirements_lock WORKSPACE
                else
                    echo "requirements_lock_${py_ver_major}_${py_ver_minor}.txt exists"
                fi

                # standard build
                bazel --max_idle_secs=1 build $TF_BUILD_FLAGS //tensorflow/tools/pip_package:wheel
                PIP_WHL_DIR="$(pwd)"/bazel-bin/tensorflow/tools/pip_package/wheel_house
            fi

            #echo "Migrating build_pip_package vs build_pip_package_py ..."
            #find -name build_pip_package.py && sed -i.bak 's!PIP_BUILD_TARGET="//tensorflow/tools/pip_package:build_pip_package"!PIP_BUILD_TARGET="//tensorflow/tools/pip_package:build_pip_package_py"!' tensorflow/tools/ci_build/builds/pip_new.sh
            #echo "Running Bazel build and creating wheel file ..."
            #. tensorflow/tools/ci_build/builds/pip_new.sh
            #echo "Bazel build finished. Creating wheel file..."
            ## Create the wheel package in /tmp/tensorflow_pkg (relative to workspace root)
            #./bazel-bin/tensorflow/tools/pip_package/build_pip_package --cpu ../tmp/tensorflow_pkg
          fi
          echo "Bazel build finished and wheel file created in ${PIP_WHL_DIR}:"
          ls "$PIP_WHL_DIR"/*.whl
          echo PIP_WHL_DIR="$PIP_WHL_DIR" >> $GITHUB_OUTPUT
      # - name: Setup tmate session for debugging
      #   if: always()
      #   uses: mxschmitt/action-tmate@v3
      #   timeout-minutes: 60
      - name: Always Shutdown Bazel Before Caching
        if: always()
        working-directory: tensorflow
        run: |
          # ls -l ~/.cache/bazel ~/.cache/bazelisk /private/var/tmp/_bazel_runner build_output/cache || true
          killall bazel
          bazel --block_for_lock shutdown
          sleep 5
          # ls -l ~/.cache/bazel ~/.cache/bazelisk /private/var/tmp/_bazel_runner build_output/cache || true
          # for path in ~/.cache/bazel ~/.cache/bazelisk /private/var/tmp/_bazel_runner tensorflow/build_output/cache
          # do
          #   if ! [ -d "$path" ]; then continue; fi
          #   find "$path" -name execroot | sudo xargs rm -rf
          #   find "$path" -name sandbox | sudo xargs rm -rf
          # done
      - name: Always Save Cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            ~/.cache/bazel
            ~/.cache/bazelisk
            /private/var/tmp/_bazel_runner
            ~/Library/Caches/bazelisk
            tensorflow/build_output/cache
          key: ${{ steps.caching.outputs.nextkey }}
      - name: Upload TensorFlow Wheel Artifact
        uses: actions/upload-artifact@v4
        with:
          name: tensorflow-noavx-tf${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}
          # Path is relative to the workspace root
          path: ${{ steps.build.outputs.PIP_WHL_DIR }}/*.whl
          retention-days: 7
  # Optional: Job to create a GitHub Release and upload the wheel there
  release:
    needs: build
    runs-on: ubuntu-22.04
    if: success() && (github.event_name == 'workflow_dispatch') # Only release on successful manual runs for now
    steps:
      - name: Download wheel artifact from build job
        uses: actions/download-artifact@v4
        with:
          name: tensorflow-noavx-tf${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}
          path: dist
      - name: Display structure of downloaded files
        run: ls -R dist
      - name: Create GitHub Release and Upload Wheel
        uses: softprops/action-gh-release@v1
        with:
          tag_name: tf-v${{ matrix.tensorflow }}-noavx-py${{ steps.setup_python.outputs.python-version }}-build${{ github.run_id }}
          name: TensorFlow ${{ matrix.tensorflow }} (No AVX) for Python ${{ matrix.python }}
          body: |
            TensorFlow wheel built from source without AVX/AVX2 instructions.
            TensorFlow Version: ${{ matrix.tensorflow }}
            Python Version: ${{ steps.setup_python.outputs.python-version }}
            Target Architecture Flags: -march=nehalem -mno-avx -mno-avx2
            Built via GitHub Actions run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          files: dist/*.whl
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  publish-to-pages:
    needs: build # Run only after the build job succeeds
    runs-on: ubuntu-22.04
    # Only publish on manual triggers or scheduled runs that succeed
    if: success() && (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    # Grant permissions for actions/checkout to push to gh-pages branch
    permissions:
      contents: write
    steps:
      - name: Download wheel artifact from build job
        uses: actions/download-artifact@v4
        with:
          # Must match the upload name in the 'build' job
          name: tensorflow-noavx-${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}
          # Download to a temporary directory
          path: ./wheel-artifact
      - name: List downloaded artifact contents
        run: ls -R ./wheel-artifact
      - name: Checkout GitHub Pages branch
        uses: actions/checkout@v4
        with:
          ref: gh-pages # The branch to publish to
          path: gh-pages # Checkout to a specific directory
      - name: Set up Python (for potential scripting)
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      - name: Create PEP 503 structure and update index
        run: |
          set -e # Exit immediately if a command exits with a non-zero status.

          # Define directories relative to the checked-out gh-pages directory
          PAGES_DIR="gh-pages"
          SIMPLE_DIR="$PAGES_DIR/simple"
          PKG_DIR="$SIMPLE_DIR/tensorflow" # Package name is 'tensorflow'

          echo "Ensuring package directory exists: $PKG_DIR"
          mkdir -p "$PKG_DIR"

          echo "Moving wheel file(s)..."
          # Find the wheel file (handle potential multiple wheels if matrix is used later)
          find ./wheel-artifact -name "*.whl" -exec mv {} "$PKG_DIR/" \;

          echo "Generating simple index: $SIMPLE_DIR/index.html"
          # This index just needs to list the package names available
          cat <<EOF > "$SIMPLE_DIR/index.html"
          <!DOCTYPE html>
          <html>
            <head>
              <title>Simple Index</title>
            </head>
            <body>
              <a href="tensorflow/">tensorflow</a><br />
            </body>
          </html>
          EOF

          echo "Generating package index: $PKG_DIR/index.html"
          # This index lists all the wheel files for the 'tensorflow' package
          # Important: Links must be relative to the index file itself
          echo '<!DOCTYPE html><html><head><title>Links for tensorflow</title></head><body><h1>Links for tensorflow</h1>' > "$PKG_DIR/index.html"
          for filename in "$PKG_DIR"/*.whl; do
            # Extract just the filename for the link text and href
            wheel_name=$(basename "$filename")
            echo "Found wheel: $wheel_name"
            # Append link to the index file
            echo "<a href=\"$wheel_name\">$wheel_name</a><br />" >> "$PKG_DIR/index.html"
          done
          echo '</body></html>' >> "$PKG_DIR/index.html"

          echo "Index files generated."
          ls -lR "$PAGES_DIR"
      - name: Commit and push changes to gh-pages
        run: |
          cd gh-pages
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          # Add all changes (new wheels, updated index files)
          git add .
          # Commit only if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Add/update TensorFlow wheel(s) and index [skip ci]"
            git push origin gh-pages
            echo "Changes pushed to gh-pages branch."
          fi
