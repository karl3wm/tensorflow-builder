name: Build
on:
  workflow_dispatch: # Allows manual triggering from the Actions tab
  schedule: # Example: Run weekly on Sunday at 03:00 UTC
    - cron: '0 3 * * 0'
  push:
    branches:
      - main
    paths:
      - '.github/workflows/**' # Only run if workflow files change
jobs:
  version_enumeration:
    runs-on: ubuntu-22.04
    outputs:
      tensorflow: ${{ steps.tensorflow.outputs.versions }}
      python: ${{ steps.python.outputs.versions }}
    steps:
      - name: Install jq
        run: sudo apt-get install jq coreutils findutils git
      - name: Fetch recent TensorFlow tags
        id: tensorflow
        run: |
          LATEST_TENSORFLOW_VERS=7
          mkdir -p tensorflow.git
          cd tensorflow.git
          git init .
          git remote add origin https://github.com/tensorflow/tensorflow
          git fetch --depth=1 --filter=tree:0 origin 'refs/tags/*:refs/tags/*'
          echo "versions=$(git tag --list --sort=-creatordate 'v*.[0-9]' | head -n $LATEST_TENSORFLOW_VERS | shuf | xargs echo -n | jq --raw-input --slurp --compact-output 'split(" ")|.[0:8]')" | tee -a $GITHUB_OUTPUT
      - name: Fetch recent Python versions
        id: python
        run: |
          SKIP_PYTHON_VERS=1
          LATEST_PYTHON_VERS=3
          mkdir -p python.git
          cd python.git
          git init .
          git remote add origin https://github.com/python/cpython
          git fetch --depth=1 --filter=tree:0 origin 'refs/heads/3.*:refs/heads/3.*'
          echo "versions=$(git branch | sort --ignore-leading-blanks --numeric --reverse --key 1.3 | tail -n +$((SKIP_PYTHON_VERS+1)) | head -n $LATEST_PYTHON_VERS | shuf | xargs echo -n | jq --raw-input --slurp --compact-output 'split(" ")|.[0:3]')" | tee -a $GITHUB_OUTPUT
  build:
    runs-on: ubuntu-22.04
    needs: version_enumeration
    strategy:
      fail-fast: false
      matrix:
        python: ${{ fromJSON(needs.version_enumeration.outputs.python) }}
        tensorflow: ${{ fromJSON(needs.version_enumeration.outputs.tensorflow) }}
    concurrency:
      group: ${{ github.run_id }}-${{ matrix.tensorflow }}
      cancel-in-progress: false
    steps:
      - name: Disable man-db/auto-update and remove some packages
        run: |
          echo "set man-db/auto-update false" | sudo debconf-communicate
          sudo dpkg-reconfigure man-db
          sudo apt-get remove --yes --quiet firefox clang\*
      - name: Set up Python ${{ matrix.python }}
        id: setup_python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python }}
      - name: Plan caching
        id: caching
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          sudo apt-get install --yes --quiet jq coreutils
          #env | sort
          KEY_PREFIX="bazel-cache-os${{ runner.os }}-tf${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}-"
          #CACHES_API="-H 'Accept: application/vnd.github+json' -H 'X-GitHub-Api-Version: 2022-11-28' /repos/${{ github.repository }}/actions/caches"
          CACHES_API="/repos/${{ github.repository }}/actions/caches"
          #for arg in gh api "${CACHES_API}"?key="$KEY_PREFIX"\&sort=size_in_bytes; do echo "- '$arg'"; done
          LATEST_KEY="$(gh api "${CACHES_API}"?key="$KEY_PREFIX"\&sort=size_in_bytes | jq -r '.actions_caches[0].key')"
          gh api "${CACHES_API}"?key="$KEY_PREFIX"\&sort=created_at | jq -r '.actions_caches[1:30][].key' | while read old_key
          do
                echo "Deleting key $old_key"
                gh api --method DELETE "${CACHES_API}"?key="$old_key"
          done
          NEXT_KEY="${KEY_PREFIX}run${{ github.run_id }}.${{ github.run_attempt }}"
          echo "Load key: $LATEST_KEY"
          echo "save key: $NEXT_KEY"
          echo "lastkey=$LATEST_KEY" >> $GITHUB_OUTPUT
          echo "nextkey=$NEXT_KEY" >> $GITHUB_OUTPUT
      # - name: Free disk space (Ubuntu)
      #   uses: jlumbroso/free-disk-space@main
      - name: Add CUDA repositories
        run: |
          . /etc/os-release
          wget --progress=dot:mega https://developer.download.nvidia.com/compute/cuda/repos/ubuntu${VERSION_ID/.}/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          rm cuda-keyring_1.1-1_all.deb
      - name: Install LLVM
        run: |
          #. /etc/os-release
          #echo "Installing clang"
          #wget --progress=dot:mega https://github.com/llvm/llvm-project/releases/download/llvmorg-17.0.2/clang+llvm-17.0.2-x86_64-linux-gnu-ubuntu-${VERSION_ID}.tar.xz -O - | xzcat | sudo tar -xvf - --directory /usr --strip-components=1
          #echo "Clang installation complete."
          #hash -r
          #type -p clang
          echo "Installing LLVM."
          wget https://apt.llvm.org/llvm.sh
          chmod +x llvm.sh
          sudo ./llvm.sh 17
          sudo update-alternatives --install /usr/bin/clang clang /usr/bin/clang-17 0
          rm llvm.sh
          echo "LLVM installation complete."
          hash -r
          readlink -f $(type -p clang)
      - name: Install system packages
        run: |
          echo "Installing system packages."
          #sudo apt-get dist-upgrade --yes --quiet # slows down build
          sudo apt-get install --yes --quiet build-essential curl git python3-dev pkg-config coreutils zip unzip xz-utils lld wget sed cuda-toolkit-12-3 cudnn-cuda-12
          echo "Done installing system packages."
      - name: Install Bazel
        run: |
          echo "Attempting to install latest Bazelisk"
          wget --progress=dot:mega https://github.com/bazelbuild/bazelisk/releases/latest/download/bazelisk-linux-amd64
          chmod +x bazelisk-linux-amd64
          sudo mv bazelisk-linux-amd64 /usr/local/bin/bazel
          echo "Bazel installation complete."
          hash -r
          type -p bazel
      #- name: Checkout TensorFlow ${{ matrix.tensorflow }}
      #  run: |
      #    git clone --filter=tree:0 --no-checkout https://github.com/tensorflow/tensorflow
      #    cd tensorflow
      #    git checkout ${{ matrix.tensorflow }} -b build
      - name: Checkout TensorFlow ${{ matrix.tensorflow }} Source Code
        uses: actions/checkout@v4
        with:
          repository: 'tensorflow/tensorflow'
          path: 'tensorflow'
          filter: 'tree:0'
          ref: ${{ matrix.tensorflow }}
      # - name: Check out ${{ matrix.tensorflow_latest }}-most recent tensorflow tag
      #   id: checkout
      #   working-directory: tensorflow
      #   run: |
      #     TF_REF="$(git tag --list --sort=-creatordate 'v*.[0-9]' | head -n ${{ matrix.tensorflow_latest }} | tail -n 1)"
      #     git checkout "$TF_REF"
      #     echo "TF_VERSION=${TF_REF#v}" >> $GITHUB_OUTPUT
      # # These outputs are used later in the run
      # - name: Generate values available at runtime
      #   id: generated
      #   working-directory: ./tensorflow
      #   run: |
      #     echo "PYTHON_BIN_PATH=$(which python)" >> $GITHUB_OUTPUT
      #     echo "PYTHON_LIB_PATH=$(python -c 'import site; print(site.getsitepackages()[0])')" >> $GITHUB_OUTPUT
      #     echo "TF_PYTHON_VERSION=$(python -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')" >> $GITHUB_OUTPUT
      #     TF_REF="$(git tag --list --sort=-creatordate 'v*.[0-9]' | head -n ${{ matrix.tensorflow_latest }} | tail -n 1)"
      #     git checkout "$TF_REF"
      #     echo "TF_VERSION=${TF_REF#v}" >> $GITHUB_OUTPUT
      # - name: Determine Bazel Version
      #   id: bazel_version
      #   working-directory: ./tensorflow
      #   run: |
      #     if [[ -f ".bazelversion" ]]; then
      #       BAZEL_VERSION_FROM_FILE=$(cat .bazelversion | head -n 1)
      #       echo "Found .bazelversion, using Bazel version: $BAZEL_VERSION_FROM_FILE"
      #       echo "bazel_version=$BAZEL_VERSION_FROM_FILE" >> $GITHUB_OUTPUT
      #     else
      #       # --- Fallback Bazel Version ---
      #       # Choose a version known to work with recent TF if .bazelversion is missing
      #       DEFAULT_BAZEL_VERSION="6.1.0"
      #       echo "WARN: .bazelversion not found in TF source for tag v${{ steps.checkout.outputs.TF_VERSION }}."
      #       echo "Using fallback Bazel version: $DEFAULT_BAZEL_VERSION"
      #       echo "bazel_version=$DEFAULT_BAZEL_VERSION" >> $GITHUB_OUTPUT
      #     fi
      - name: Restore Cache
        uses: actions/cache/restore@v4
        with:
          path: |
            ~/.cache/bazel
            ~/.cache/bazelisk
            tensorflow/build_output/cache
          key: ${{ steps.caching.outputs.lastkey }}
      # - name: Dump Configuration and Environment (Troubleshooting)
      #   run: |
      #     echo "--- System Info ---"
      #     uname -a
      #     lsb_release -a
      #     echo "--- Tool Versions ---"
      #     python --version
      #     pip --version
      #     bazel version || echo "Bazel not found or failed"
      #     gcc --version || echo "GCC not found or failed"
      #     g++ --version || echo "G++ not found or failed"
      #     clang --version || echo "Clang not found or failed"
      #     ldd --version || echo "ldd not found or failed" # GNU ld version
      #     ld.lld --version || echo "ld.lld not found or failed" # LLVM linker version
      #     echo "--- Key Environment Variables ---"
      #     echo "PATH=$PATH"
      #     echo "PYTHON_BIN_PATH=${{ steps.generated.outputs.PYTHON_BIN_PATH }}"
      #     echo "PYTHON_LIB_PATH=${{ steps.generated.outputs.PYTHON_LIB_PATH }}"
      #     echo "TF_PYTHON_VERSION=${{ steps.generated.outputs.TF_PYTHON_VERSION }}"
      #     printenv | grep TF_ || echo "No TF_ environment variables set yet"
      #     printenv | grep CC_ || echo "No CC_ environment variables set yet"
      #     echo "--- Python Site Packages ---"
      #     ls -l ${{ steps.generated.outputs.PYTHON_LIB_PATH }} || echo "Could not list site-packages"
      # ---------------------------------------------------------------------
      # Tmate Debugging Step - uncomment/comment as needed
      # This will pause the workflow and output SSH connection details
      # Connect to the runner to manually inspect the environment and run commands
      # - name: Setup tmate session for debugging
      #   uses: mxschmitt/action-tmate@v3
      #   timeout-minutes: 60
      # ---------------------------------------------------------------------
      - name: Configure and build TensorFlow
        id: build
        working-directory: ./tensorflow
        timeout-minutes: 300 # GitHub Actions maximum for free tier is 6 hours/job
        #timeout-minutes: 5 # short timeout for development
        # env:
        #   # Environment variables for TensorFlow's configure script (non-interactive)
        #   PYTHON_BIN_PATH: ${{ steps.generated.outputs.PYTHON_BIN_PATH }}
        #   PYTHON_LIB_PATH: ${{ steps.generated.outputs.PYTHON_LIB_PATH }}
        #   TF_PYTHON_VERSION: ${{ steps.generated.outputs.TF_PYTHON_VERSION }}
        #   TF_ENABLE_XLA: '1'
        #   TF_NEED_CUDA: '0'
        #   TF_NEED_ROCM: '0'
        #   # Let Bazel decide on Clang download/use by default
        #   # TF_DOWNLOAD_CLANG: '0'
        #   # Remove explicit GCC paths to allow Bazel to potentially pick Clang
        #   # GCC_HOST_COMPILER_PATH: /usr/bin/gcc
        #   # HOST_CXX_COMPILER_PATH: /usr/bin/g++
        #   TF_CONFIGURE_IOS: '0'
        #   TF_SET_ANDROID_WORKSPACE: '0'
        #   # --- CRUCIAL: Compiler flags to disable AVX/AVX2 ---
        #   # Target Nehalem (SSE4.2 baseline before AVX). Adjust if needed.
        #   CC_OPT_FLAGS: '-march=nehalem -mno-avx -mno-avx2 -O3'
        #   TF_BUILD_FLAGS: "--config=monolithic --config=opt --copt=-march=nehalem --copt=-mno-avx --copt=-mno-avx2 --copt=-O3 --verbose_failures" # --toolchain_resolution_debug=@bazel_tools//tools/cpp:toolchain_type --subcommands # Build the pip package with enhanced verbosity
        #   TF_NEED_OPENCL_SYCL: '0'
        #   TF_NEED_COMPUTECPP: '0'
        #   TF_NEED_MPI: '0'
        #   TF_NEED_TENSORRT: '0'
        #   CONTAINER_TYPE: cpu # cpu gpu rocm
        #   OS_TYPE: ubuntu # ubuntu macos
        #   IS_NIGHTLY: 0
        #   TF_PROJECT_NAME: "tensorflow_noavx"
        #   KOKORO_ARTIFACTS_DIR: ../tmp
        #   TF_TEST_FLAGS: "--verbose_failures=true --build_tests_only --test_output=errors"
        #   TF_TEST_FILTER_TAGS: "-no_oss,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test"
        #   TF_TEST_TARGETS: "//tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/..."
        #   #HERMETIC_PYTHON_VERSION: ${{ steps.generated.outputs.TF_PYTHON_VERSION }}
        #   #WHEEL_NAME: tensorflow_noavx_cpu
        run: |
          # if [ -d ci/official/envs ]
          # then # ci infrastructure in this version
          #   echo "TFCI_PYTHON_VERSION=$(python -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')" > ci/official/envs/py_custom
          #   echo 'TFCI_BAZEL_COMMON_ARGS="$TFCI_BAZEL_COMMON_ARGS --config=monolithic --copt=-march=nehalem --copt=-mno-avx --copt=-mno-avx2 --copt=-O3 --verbose_failures"' > ci/official/envs/noavx_custom
          #   echo 'TFCI_BUILD_PIP_PACKAGE_WHEEL_NAME_ARG="${TFCI_BUILD_PIP_PACKAGE_WHEEL_NAME_ARG/tensorflow/tensorflow_noavx}"' >> ci/official/envs/noavx_custom
          #   echo 'TFCI_INSTALLER_WHL_PROJECT_NAME="${TFCI_INSTALLER_WHL_PROJECT_NAME/tensorflow/tensorflow_noavx}"' >> ci/official/envs/noavx_custom
          #   for envfile in py_custom linux_x86 disk_cache no_docker noavx_custom
          #   do
          #     echo "$envfile":
          #     cat ci/official/envs/"$envfile"
          #   done
          #   echo "Running Bazel build and creating wheel file ..."
          #   TFCI=py_custom,linux_x86,disk_cache,no_docker,noavx_custom ci/official/wheel.sh
          #   PIP_WHL_DIR="$(pwd)/build_output"
          # else # build manually
          if true
          then
            echo "Running ./configure with environment variables:"
            export TF_ENABLE_XLA=1 TF_NEED_CUDA=0 TF_NEED_ROCM=0 TF_CONFIGURE_IOS=0 TF_SET_ANDROID_WORKSPACE=0
            export CC_OPT_FLAGS='-march=nehalem -mno-avx -mno-avx2 -O3'
            export TF_BUILD_FLAGS="--config=monolithic --config=opt --verbose_failures" # --toolchain_resolution_debug=@bazel_tools//tools/cpp:toolchain_type --subcommands # Build the pip package with enhanced verbosity
            export HERMETIC_PYTHON_VERSION=${{ matrix.python }}
            export TF_PROJECT_NAME=tensorflow_noavx_cpu
            export PROJECT_NAME="$TF_PROJECT_NAME"
            export WHEEL_NAME="$TF_PROJECT_NAME"
            printenv | grep TF_ # Show TF vars being used
            printenv | grep CC_OPT_FLAGS # Show compiler flags being used
            ./configure
            echo "Configure finished."

            py_ver_major=${HERMETIC_PYTHON_VERSION%.*}
            py_ver_minor=${HERMETIC_PYTHON_VERSION#*.}
            if ! [ -e requirements_lock_${py_ver_major}_${py_ver_minor}.txt ]
            then
                for offset in 1 -1 2 -2
                do
                        py_ver_alternate=$((py_ver_minor+offset))
                        if [ -e requirements_lock_${py_ver_major}_${py_ver_alternate}.txt ]
                        then
                                break
                        fi
                done
                find -name requirements_lock_${py_ver_major}_${py_ver_alternate}.txt | while read fn
                do
                        #cp -v "$fn" "${fn%_*}_${py_ver_minor}.txt"
                        # filter out tensorflow-built dependencies which won't be available
                        REQUIREMENTSFN="${fn%_*}_${py_ver_minor}.txt"
                        grep --invert-match '^tensorflow' ci/official/requirements_updater/requirements.in | tee "$REQUIREMENTSFN"
                        python${HERMETIC_PYTHON_VERSION} -m pip install -r "$REQUIREMENTSFN"
                done
                sed -i "s/\"${py_ver_major}\.${py_ver_alternate}\"/\"${py_ver_major}.${py_ver_minor}\"/g; s/_lock_${py_ver_major}_${py_ver_alternate}\.txt/_lock_${py_ver_major}_${py_ver_minor}.txt/g" WORKSPACE
                grep requirements_lock WORKSPACE
                bazel run //ci/official/requirements_updater:requirements.update # uses HERMETIC_PYTHON_VERSION
            else
                echo "requirements_lock_${py_ver_major}_${py_ver_minor}.txt exists"
            fi

            if [ -e tensorflow/tools/pip_package/build_pip_package.sh ]
            then
                # < 2.17
                # The documentation for building tensorflow 2.16 is in commit 57a0d991e684cd01cec3ac152112a7df3a18a26a of the tensorflow docs repository
                bazel build $TF_BUILD_FLAGS //tensorflow/tools/pip_package:build_pip_package
                PIP_WHL_DIR=/tmp/tensorflow_pkg
                ./bazel-bin/tensorflow/tools/pip_package/build_pip_package "$PIP_WHL_DIR"
            else
                # >= 2.17
                bazel build $TF_BUILD_FLAGS //tensorflow/tools/pip_package:wheel
                PIP_WHL_DIR="$(pwd)"/bazel-bin/tensorflow/tools/pip_package/wheel_house
            fi

            #echo "Migrating build_pip_package vs build_pip_package_py ..."
            #find -name build_pip_package.py && sed -i 's!PIP_BUILD_TARGET="//tensorflow/tools/pip_package:build_pip_package"!PIP_BUILD_TARGET="//tensorflow/tools/pip_package:build_pip_package_py"!' tensorflow/tools/ci_build/builds/pip_new.sh
            #echo "Running Bazel build and creating wheel file ..."
            #. tensorflow/tools/ci_build/builds/pip_new.sh
            #echo "Bazel build finished. Creating wheel file..."
            ## Create the wheel package in /tmp/tensorflow_pkg (relative to workspace root)
            #./bazel-bin/tensorflow/tools/pip_package/build_pip_package --cpu ../tmp/tensorflow_pkg
          fi
          echo "Bazel build finished and wheel file created in ${PIP_WHL_DIR}:"
          ls "$PIP_WHL_DIR"/*.whl
          echo PIP_WHL_DIR="$PIP_WHL_DIR" >> $GITHUB_OUTPUT
      - name: Always Remove Inaccessible Files Prior To Saving Cache
        if: always()
        run: |
          for path in ~/.cache/bazel ~/.cache/bazelisk tensorflow/build_output/cache
          do
            if ! [ -d "$path" ]; then continue; fi
            find "$path" -name execroot | sudo xargs rm -rf
            find "$path" -name sandbox | sudo xargs rm -rf
          done
      - name: Always Save Cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            ~/.cache/bazel
            ~/.cache/bazelisk
            tensorflow/build_output/cache
          key: ${{ steps.caching.outputs.nextkey }}
      - name: Upload TensorFlow Wheel Artifact
        uses: actions/upload-artifact@v4
        with:
          name: tensorflow-noavx-tf${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}
          # Path is relative to the workspace root
          path: ${{ steps.build.outputs.PIP_WHL_DIR }}/*.whl
          retention-days: 7
  # Optional: Job to create a GitHub Release and upload the wheel there
  release:
    needs: build
    runs-on: ubuntu-22.04
    if: success() && (github.event_name == 'workflow_dispatch') # Only release on successful manual runs for now
    steps:
      - name: Download wheel artifact from build job
        uses: actions/download-artifact@v4
        with:
          name: tensorflow-noavx-tf${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}
          path: dist
      - name: Display structure of downloaded files
        run: ls -R dist
      - name: Create GitHub Release and Upload Wheel
        uses: softprops/action-gh-release@v1
        with:
          tag_name: tf-v${{ matrix.tensorflow }}-noavx-py${{ steps.setup_python.outputs.python-version }}-build${{ github.run_id }}
          name: TensorFlow ${{ matrix.tensorflow }} (No AVX) for Python ${{ matrix.python }}
          body: |
            TensorFlow wheel built from source without AVX/AVX2 instructions.
            TensorFlow Version: ${{ matrix.tensorflow }}
            Python Version: ${{ steps.setup_python.outputs.python-version }}
            Target Architecture Flags: -march=nehalem -mno-avx -mno-avx2
            Built via GitHub Actions run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          files: dist/*.whl
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  publish-to-pages:
    needs: build # Run only after the build job succeeds
    runs-on: ubuntu-22.04
    # Only publish on manual triggers or scheduled runs that succeed
    if: success() && (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    # Grant permissions for actions/checkout to push to gh-pages branch
    permissions:
      contents: write
    steps:
      - name: Download wheel artifact from build job
        uses: actions/download-artifact@v4
        with:
          # Must match the upload name in the 'build' job
          name: tensorflow-noavx-${{ matrix.tensorflow }}-py${{ steps.setup_python.outputs.python-version }}
          # Download to a temporary directory
          path: ./wheel-artifact
      - name: List downloaded artifact contents
        run: ls -R ./wheel-artifact
      - name: Checkout GitHub Pages branch
        uses: actions/checkout@v4
        with:
          ref: gh-pages # The branch to publish to
          path: gh-pages # Checkout to a specific directory
      - name: Set up Python (for potential scripting)
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      - name: Create PEP 503 structure and update index
        shell: bash # Use bash for scripting
        run: |
          set -e # Exit immediately if a command exits with a non-zero status.

          # Define directories relative to the checked-out gh-pages directory
          PAGES_DIR="gh-pages"
          SIMPLE_DIR="$PAGES_DIR/simple"
          PKG_DIR="$SIMPLE_DIR/tensorflow" # Package name is 'tensorflow'

          echo "Ensuring package directory exists: $PKG_DIR"
          mkdir -p "$PKG_DIR"

          echo "Moving wheel file(s)..."
          # Find the wheel file (handle potential multiple wheels if matrix is used later)
          find ./wheel-artifact -name "*.whl" -exec mv {} "$PKG_DIR/" \;

          echo "Generating simple index: $SIMPLE_DIR/index.html"
          # This index just needs to list the package names available
          cat <<EOF > "$SIMPLE_DIR/index.html"
          <!DOCTYPE html>
          <html>
            <head>
              <title>Simple Index</title>
            </head>
            <body>
              <a href="tensorflow/">tensorflow</a><br />
            </body>
          </html>
          EOF

          echo "Generating package index: $PKG_DIR/index.html"
          # This index lists all the wheel files for the 'tensorflow' package
          # Important: Links must be relative to the index file itself
          echo '<!DOCTYPE html><html><head><title>Links for tensorflow</title></head><body><h1>Links for tensorflow</h1>' > "$PKG_DIR/index.html"
          for filename in "$PKG_DIR"/*.whl; do
            # Extract just the filename for the link text and href
            wheel_name=$(basename "$filename")
            echo "Found wheel: $wheel_name"
            # Append link to the index file
            echo "<a href=\"$wheel_name\">$wheel_name</a><br />" >> "$PKG_DIR/index.html"
          done
          echo '</body></html>' >> "$PKG_DIR/index.html"

          echo "Index files generated."
          ls -lR "$PAGES_DIR"
      - name: Commit and push changes to gh-pages
        run: |
          cd gh-pages
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          # Add all changes (new wheels, updated index files)
          git add .
          # Commit only if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Add/update TensorFlow wheel(s) and index [skip ci]"
            git push origin gh-pages
            echo "Changes pushed to gh-pages branch."
          fi
